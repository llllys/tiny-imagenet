{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Optimizer\n","from torch.autograd import Variable\n","import math\n","import cv2\n","from torchvision import transforms, models\n","\n","import matplotlib.pyplot as plt\n","import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#    for filename in filenames:\n","        #print(os.path.join(dirname, filename))\n","# we are using Kaggle kernel"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["path = '../input/tiny-imagenet-challenge/TinyImageNet/'"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["train_label = pd.read_csv(path+'train.txt', sep=' ', names=['image', 'label'])\n","test = pd.read_csv(path+'test.txt', sep=' ', names=['image'])\n","val_label = pd.read_csv(path+'val.txt', sep=' ', names=['image', 'label'])\n","\n","print('train size: ', train_label.shape)\n","print('val size: ', val_label.shape)\n","print('test size: ', test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class data(Dataset):\n","    def __init__(self, type, transform):\n","        self.type = type\n","        if type == 'train':\n","            self.train_images = []\n","            for row in train_label.itertuples(index=True, name='Pandas'):\n","                # print(getattr(row, 'image'))\n","                image_path = os.path.join(path, getattr(row, 'image'))\n","                self.train_images.append(cv2.imread(image_path))\n","            self.train_images = np.array(self.train_images)\n","            \n","        elif type == 'val':\n","            self.val_images = []\n","            for row in val_label.itertuples(index=True, name='Pandas'):\n","                # print(getattr(row, 'image'))\n","                image_path = os.path.join(path, getattr(row, 'image'))\n","                self.val_images.append(cv2.imread(image_path))\n","            self.val_images = np.array(self.val_images)\n","            \n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        label = []\n","        image = []\n","        if self.type == 'train':\n","            label = train_label.loc[index, 'label']\n","            image = self.train_images[index]\n","        if self.type == 'val':\n","            label = val_label.loc[index, 'label']\n","            image = self.val_images[index]\n","        return self.transform(image), label \n","        \n","    def __len__(self):\n","        length = 0\n","        if self.type == 'train':\n","            length = self.train_images.shape[0]\n","        if self.type == 'val':\n","            length = self.val_images.shape[0]\n","        return length\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_dataset = data('train', transform=transforms.ToTensor())\n","val_dataset = data('val', transform=transforms.ToTensor())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["batch_size = 128\n","val_batch_size = 128\n","\n","train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(dataset=val_dataset, batch_size=val_batch_size, shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class Mymodel(nn.Module):\n","    def __init__(self):\n","        super(Mymodel, self).__init__()\n","        self.resnet = model.resnet50() # pretrained model from torchvision\n","        self.linear1 = torch.nn.Linear(in_features=1000, out_features=512)\n","        self.linear2 = torch.nn.Linear(in_features=512, out_features=256)\n","        self.linear3 = torch.nn.Linear(in_features=256, out_features=100)\n","        \n","    def forward(self, x):\n","        x = self.se_resnet(x)\n","        x = F.relu(x)\n","        x = self.linear1(x)\n","        x = F.relu(x)\n","        x = self.linear2(x)\n","        x = F.relu(x)\n","        x = self.linear3(x)\n","        \n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def build_model(path):\n","    #加载预训练参数\n","    resnet_state_dict = torch.load(path)\n","    model = Mymodel()\n","    model.load_state_dict(resnet_state_dict)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mdoel = build_model(path='../input/resnet50/resnet50.pth')\n","print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["max_epoch = 20"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["use_gpu = torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Train_Accuracy = []\n","Val_Accuracy = []\n","Train_Loss = []\n","Val_Loss = []"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if use_gpu:\n","    model = model.cuda()\n","\n","criterion = nn.CrossEntropyLoss() \n","# optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.95)\n","optimizer = optim.Adam(model.parameters(), lr=0.0005, betas=(0.9, 0.999), weight_decay=1e-5)\n","\n","\n","    \n","for epoch in range(max_epoch):\n","    train_acc_sum = 0\n","    train_sum = 0\n","    val_acc_sum = 0\n","    val_sum = 0\n","    train_Accuracy = []\n","    val_Accuracy = []\n","    train_Loss = []\n","    val_Loss = []\n","\n","    model.train()\n","    print('***Training***')\n","    for i, data in enumerate(train_dataloader, 0):\n","        # get the inputs\n","        inputs, labels = data\n","        if use_gpu:\n","            inputs = inputs.cuda()\n","            labels = labels.cuda()\n","            \n","        # wrap them in Variable\n","        inputs, labels = Variable(inputs), Variable(labels)\n","        \n","        # Forward pass: Compute predicted y by passing X to the model\n","        y_pred = model(inputs)\n","        y_predict = y_pred.argmax(axis=1)\n","        \n","        train_acc_sum += float(sum(y_predict == labels))\n","        train_sum += float(len(labels))\n","        \n","        acc = train_acc_sum / float(train_sum)\n","        train_Accuracy.append(acc)\n","        \n","        # Compute and print Loss\n","        loss = criterion(y_pred, labels)\n","        if use_gpu: loss = loss.cpu()\n","        train_Loss.append(loss)\n","        \n","        if i % 100 == 0: \n","            print('Epoch: {}\\t Batch: {}\\t Loss: {:.4f}\\t Accuracy: {:.4f} '.format(epoch, i, loss, acc))\n","        \n","        # Zero gradients, perform a backward pass, and update the weights.\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    Train_Loss.append(float(torch.stack(train_Loss).mean()))\n","    Train_Accuracy.append(np.array(train_Accuracy).mean())\n","    \n","    torch.cuda.empty_cache()\n","    ################################\n","    with torch.no_grad():\n","        model.eval()\n","        print('***Validating***')\n","        for i, data in enumerate(val_dataloader, 0):\n","            # get the inputs\n","            inputs, labels = data\n","            if use_gpu:\n","                inputs = inputs.cuda()\n","                labels = labels.cuda()\n","\n","            # wrap them in Variable\n","            inputs, labels = Variable(inputs), Variable(labels)\n","\n","            # Forward pass: Compute predicted y by passing X to the model\n","            y_pred = model(inputs)\n","            y_predict = y_pred.argmax(axis=1)\n","\n","            val_acc_sum += float(sum(y_predict == labels))\n","            val_sum += float(len(labels))\n","            acc = val_acc_sum / float(val_sum)\n","            val_Accuracy.append(acc)\n","\n","            loss = criterion(y_pred, labels)\n","            if use_gpu: loss = loss.cpu()\n","            val_Loss.append(loss)\n","\n","            if i % 10 == 0: \n","                print('Epoch: {}\\t Batch: {}\\t Loss: {:.4f}\\t Accuracy: {:.4f} '.format(epoch, i, loss, acc))\n","\n","        Val_Loss.append(float(torch.stack(val_Loss).mean()))\n","        Val_Accuracy.append(np.array(val_Accuracy).mean())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(),'./my_resnet50.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot loss curve and accuracy curve"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class test_data(Dataset):\n","    def __init__(self, transform):\n","        self.test_images = []\n","        self.id = []\n","        for row in test.itertuples(index=True, name='Pandas'):\n","            # print(getattr(row, 'image'))\n","            image_path = os.path.join(path, getattr(row, 'image'))\n","            self.test_images.append(cv2.imread(image_path))\n","            self.id.append(getattr(row, 'image').replace('test/', ''))\n","        self.test_images = np.array(self.test_images)\n","        self.id = np.array(self.id)\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        label = self.id[index]\n","        image = self.test_images[index]\n","        return self.transform(image), label \n","        \n","    def __len__(self):\n","        length = 0   \n","        length = self.test_images.shape[0]\n","        return length\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_dataset = test_data(transform=transforms.ToTensor())\n","test_dataloader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Test_Sub = []\n","ID = []\n","with torch.no_grad():\n","    torch.cuda.empty_cache()\n","    model = model.cuda()\n","    for i, data in enumerate(test_dataloader, 0):\n","        # get the inputs\n","        inputs, ids = data\n","        if use_gpu:\n","            inputs = inputs.cuda()\n","            \n","        inputs = Variable(inputs)\n","        test_pred = model(inputs)\n","        test_sub = test_pred.argmax(axis=1)  \n","        test_sub = test_sub.cpu()\n","        Test_Sub = np.append(Test_Sub, test_sub)\n","        ID = np.append(ID, ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["my_submission = pd.DataFrame({'Id': ID, 'Category': Test_Sub})\n","my_submission.to_csv('./submission.csv', index=False)"]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}